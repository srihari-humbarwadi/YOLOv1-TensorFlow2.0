{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = 608, 608\n",
    "grid_size = [H//32, W//32]\n",
    "nboxes = 9\n",
    "classes = ['bike', 'bus', 'car', 'motor', 'person', 'rider', 'traffic light', 'traffic sign', 'train', 'truck']\n",
    "class_map = {k:idx for idx,k in enumerate(classes)}\n",
    "nclasses = len(class_map)\n",
    "output_shape = grid_size + [nboxes*5 + nclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxes1, boxes2):\n",
    "    boxes1_t = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                         boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                         boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                         boxes1[..., 1] + boxes1[..., 3] / 2.0],\n",
    "                        axis=-1)\n",
    "\n",
    "    boxes2_t = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                         boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                         boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                         boxes2[..., 1] + boxes2[..., 3] / 2.0],\n",
    "                        axis=-1)\n",
    "\n",
    "    # calculate the left up point & right down point\n",
    "    lu = tf.maximum(boxes1_t[..., :2], boxes2_t[..., :2])\n",
    "    rd = tf.minimum(boxes1_t[..., 2:], boxes2_t[..., 2:])\n",
    "\n",
    "    # intersection\n",
    "    intersection = tf.maximum(0.0, rd - lu)\n",
    "    inter_square = intersection[..., 0] * intersection[..., 1]\n",
    "\n",
    "    # calculate the boxs1 square and boxs2 square\n",
    "    square1 = boxes1[..., 2] * boxes1[..., 3]\n",
    "    square2 = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    union_square = tf.maximum(square1 + square2 - inter_square, 1e-10)\n",
    "\n",
    "    return tf.clip_by_value(inter_square / union_square, 0.0, 1.0)    \n",
    "\n",
    "offset = []\n",
    "offset_tran = []\n",
    "for i in range(grid_size[0]):\n",
    "    row = []\n",
    "    row_trans = []\n",
    "    for j in range(grid_size[0]):\n",
    "        row.append(j)\n",
    "        row_trans.append(i)\n",
    "    offset.append(row)\n",
    "    offset_tran.append(row_trans)\n",
    "offset = np.tile(np.array(offset)[None, :, :, None], reps=[1,1,1,nboxes])\n",
    "offset_tran = np.tile(np.array(offset_tran)[None, :, :, None], reps=[1,1,1,nboxes])\n",
    "\n",
    "offset = tf.constant(offset, dtype=tf.float32)\n",
    "offset_tran = tf.constant(offset_tran, dtype=tf.float32)\n",
    "\n",
    "def Yolo_Loss(y_true=None, y_pred=None, eval=False):\n",
    "    pred_obj_conf = y_pred[:,:,:,:nboxes]\n",
    "    pred_box_classes = y_pred[:,:,:,5*nboxes:]\n",
    "    pred_box_offset_coord = y_pred[:,:,:, nboxes:5*nboxes]\n",
    "    pred_box_offset_coord = tf.reshape(pred_box_offset_coord, shape=[-1, grid_size[0], grid_size[0], nboxes, 4])\n",
    "    pred_box_normalized_coord = tf.stack([(pred_box_offset_coord[:,:,:,:,0] + offset)/grid_size[0],\n",
    "                                         (pred_box_offset_coord[:,:,:,:,1] + offset_tran)/grid_size[0],\n",
    "                                         tf.square(pred_box_offset_coord[:,:,:,:,2]),\n",
    "                                         tf.square(pred_box_offset_coord[:,:,:,:,3])], axis=-1)\n",
    "    if eval:\n",
    "        return pred_obj_conf, pred_box_classes, pred_box_normalized_coord\n",
    "    target_obj_conf = y_true[:,:,:,:1]\n",
    "    target_box_classes = y_true[:,:,:,5:]\n",
    "    target_box_coord = y_true[:,:,:,1:5]\n",
    "    target_box_coord = tf.reshape(target_box_coord, shape=[-1, grid_size[0], grid_size[1], 1, 4])\n",
    "    target_box_coord = tf.tile(target_box_coord, multiples=[1,1,1,nboxes,1])\n",
    "    target_box_normalized_coord = target_box_coord / H\n",
    "    target_box_offset_coord = tf.stack([target_box_normalized_coord[:,:,:,:,0]*grid_size[0] - offset,\n",
    "                                        target_box_normalized_coord[:,:,:,:,1]*grid_size[0] - offset_tran,\n",
    "                                        tf.sqrt(target_box_normalized_coord[:,:,:,:,2]),\n",
    "                                        tf.sqrt(target_box_normalized_coord[:,:,:,:,3])], axis=-1)\n",
    "\n",
    "    pred_ious = compute_iou(target_box_normalized_coord, pred_box_normalized_coord)\n",
    "    predictor_mask = tf.reduce_max(pred_ious, axis=3, keepdims=True)\n",
    "    predictor_mask = tf.cast(pred_ious>=predictor_mask, tf.float32) * target_obj_conf\n",
    "    noobj_mask = tf.ones_like(predictor_mask) - predictor_mask\n",
    "\n",
    "    # Computing the class loss\n",
    "    class_loss = tf.reduce_mean(tf.reduce_sum(tf.square(target_obj_conf*(target_box_classes - pred_box_classes)), axis=[1, 2, 3]))\n",
    "\n",
    "    # computing the confidence loss\n",
    "    obj_loss = tf.reduce_mean(tf.reduce_sum(tf.square(predictor_mask*(pred_obj_conf - pred_ious)), axis=[1, 2, 3]))\n",
    "    noobj_loss = tf.reduce_mean(tf.reduce_sum(tf.square(noobj_mask*(pred_obj_conf)), axis=[1, 2, 3]))\n",
    "\n",
    "    # computing the localization loss\n",
    "    predictor_mask = predictor_mask[:,:,:,:,None]\n",
    "    loc_loss = tf.reduce_mean(tf.reduce_sum(tf.square(predictor_mask*(target_box_offset_coord - pred_box_offset_coord)), axis=[1, 2, 3]))\n",
    "\n",
    "    loss = 10 * loc_loss + obj_loss + 0.1 * noobj_loss + 0.5 * class_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(glob('/home/mia/backup/research/autonomous_driving/BDD/bdd100k/images/100k/train/*'))\n",
    "train_labels = sorted(glob('/home/mia/backup/research/autonomous_driving/BDD/bdd100k/labels/100k/train/*'))\n",
    "\n",
    "val_images = sorted(glob('/home/mia/backup/research/autonomous_driving/BDD/bdd100k/images/100k/val/*'))\n",
    "val_labels = sorted(glob('/home/mia/backup/research/autonomous_driving/BDD/bdd100k/labels/100k/val/*'))\n",
    "\n",
    "batch_size = 24\n",
    "train_steps = len(train_images) // batch_size\n",
    "val_steps = len(val_images) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(label_path, orig_h=720, orig_w=1280):\n",
    "    label = np.zeros(shape=[*grid_size, 5+nclasses])\n",
    "    with open(label_path, 'r') as f:\n",
    "        temp = json.load(f)\n",
    "    for obj in temp['frames'][0]['objects']:\n",
    "        if 'box2d' in obj:\n",
    "            x1 = obj['box2d']['x1'] * W / orig_w\n",
    "            y1 = obj['box2d']['y1'] * H / orig_h\n",
    "            x2 = obj['box2d']['x2'] * W / orig_w\n",
    "            y2 = obj['box2d']['y2'] * H / orig_h\n",
    "            x = (x2 + x1) / 2\n",
    "            y = (y2 + y1) / 2\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            category_id = class_map[obj['category']]\n",
    "            class_vector = np.zeros((nclasses, ))\n",
    "            class_vector[category_id] = 1\n",
    "            label_vector = [1, x, y, w, h, *class_vector]\n",
    "            grid_x = int(x / W * grid_size[1])\n",
    "            grid_y = int(y / H * grid_size[0])\n",
    "            try:\n",
    "                label[grid_y, grid_x] = label_vector\n",
    "            except:\n",
    "                continue\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70000it [00:11, 6020.89it/s]\n",
      "10000it [00:01, 6029.12it/s]\n"
     ]
    }
   ],
   "source": [
    "train_label_vectors = np.zeros(shape=[len(train_images), *grid_size, 5+nclasses])\n",
    "for i, img in tqdm(enumerate(train_images)):\n",
    "    fname = img.split('/')[-1].split('.')[0] + '.json'\n",
    "    label_path = '/home/mia/backup/research/autonomous_driving/BDD/bdd100k/labels/100k/train/' + fname\n",
    "    train_label_vectors[i] = get_label(label_path)\n",
    "\n",
    "val_label_vectors = np.zeros(shape=[len(val_images), *grid_size, 5+nclasses])\n",
    "for i, img in tqdm(enumerate(val_images)):\n",
    "    fname = img.split('/')[-1].split('.')[0] + '.json'\n",
    "    label_path = '/home/mia/backup/research/autonomous_driving/BDD/bdd100k/labels/100k/val/' + fname\n",
    "    val_label_vectors[i] = get_label(label_path)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path, flip=False):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.cast(tf.image.resize(img, size=[H, W]), dtype=tf.float32)\n",
    "    img = tf.image.random_brightness(img, max_delta=50.)\n",
    "    img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
    "    img = tf.image.random_hue(img, max_delta=0.2)\n",
    "    img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
    "    if flip:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "    img = tf.clip_by_value(img, 0, 255)\n",
    "    img /= 127.5\n",
    "    img -= 1.\n",
    "    return img\n",
    "\n",
    "def flip_labels(labels, flip=False):\n",
    "    if flip:\n",
    "        temp = labels[labels[:, :, 0] == 1]\n",
    "        temp[:, 1] = W - temp[:, 1]\n",
    "        labels[labels[:, :, 0] == 1] = temp\n",
    "    return labels\n",
    "\n",
    "def load_data(image_path, labels):\n",
    "    flip = tf.cast(tf.random.uniform(shape=[1,], minval=0, maxval=2, dtype=tf.int32), dtype=tf.bool).numpy()[0]\n",
    "    return get_image(image_path, flip=flip), flip_labels(labels, flip=flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mia/tf-trt/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "def conv_block(x, n_filters, size, pool=False):\n",
    "    x = Conv2D(filters=n_filters,\n",
    "               kernel_size=size,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    if pool:\n",
    "        x = MaxPool2D(pool_size=2)(x)\n",
    "    return x\n",
    "\n",
    "input_layer = Input(shape=(H, W, 3))\n",
    "x = conv_block(input_layer, 32, 3, pool=True)\n",
    "x = conv_block(x, 64, 3, pool=True)\n",
    "x = conv_block(x, 128, 3)\n",
    "x = conv_block(x, 64, 1)\n",
    "x = conv_block(x, 128, 3, pool=True)\n",
    "x = conv_block(x, 256, 3)\n",
    "x = conv_block(x, 128, 1)\n",
    "x = conv_block(x, 256, 3, pool=True)\n",
    "x = conv_block(x, 512, 3)\n",
    "x = conv_block(x, 256, 1)\n",
    "x = conv_block(x, 512, 3)\n",
    "x = conv_block(x, 256, 1)\n",
    "\n",
    "skip = Lambda(lambda tensor : tf.nn.space_to_depth(tensor, block_size=2))(x)\n",
    "\n",
    "x = conv_block(x, 512, 3, pool=True)\n",
    "x = conv_block(x, 1024, 3)\n",
    "x = conv_block(x, 512, 1)\n",
    "x = conv_block(x, 1024, 3)\n",
    "x = conv_block(x, 512, 1)\n",
    "x = conv_block(x, 1024, 3)\n",
    "x = conv_block(x, 1024, 3)\n",
    "x = conv_block(x, 1024, 3)\n",
    "x = concatenate([x, skip])\n",
    "x = conv_block(x, 1024, 3)\n",
    "\n",
    "output_layer = Conv2D(output_shape[-1], kernel_size=1)(x)\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='Yolo')\n",
    "model.load_weights('model/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_label_vectors))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=256)\n",
    "train_dataset = train_dataset.apply(tf.data.experimental.map_and_batch(map_func=load_data, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   num_parallel_calls=64,\n",
    "                                                   drop_remainder=True))\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.prefetch(-1)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_label_vectors))\n",
    "val_dataset = val_dataset.shuffle(buffer_size=256)\n",
    "val_dataset = val_dataset.apply(tf.data.experimental.map_and_batch(map_func=load_data,\n",
    "                                                   batch_size=batch_size, \n",
    "                                                   num_parallel_calls=64,\n",
    "                                                   drop_remainder=True))\n",
    "val_dataset = train_dataset.repeat()\n",
    "val_dataset = train_dataset.prefetch(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r model/*\n",
    "# callbacks = [tf.keras.callbacks.ModelCheckpoint('model/weights.h5', save_best_only=True, save_weights_only=True)]\n",
    "# model.fit(train_dataset,\n",
    "#          steps_per_epoch=train_steps,\n",
    "#          epochs=300, \n",
    "#          validation_data=val_dataset,\n",
    "#          validation_steps=val_steps, \n",
    "#          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {v:k for k,v in class_map.items()}\n",
    "\n",
    "def read_img(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.cast(tf.image.resize(img, size=[H, W]), dtype=tf.float32)\n",
    "    return img.numpy()\n",
    "\n",
    "def visualize(img, pred, iou=0.5, score_threshold=0.5, label_map={}, orig_h=720, orig_w=1280, resize=True, video=True):\n",
    "    predict_object, predict_class, predict_normalized_box  = Yolo_Loss(pred, pred, eval=True)\n",
    "    predict_object, predict_class, predict_normalized_box = predict_object[0], predict_class[0], predict_normalized_box[0].numpy()\n",
    "    if not resize:\n",
    "        predict_normalized_box = predict_normalized_box * H\n",
    "    else:\n",
    "        img = cv2.resize(img, (orig_w, orig_h))\n",
    "        predict_normalized_box[...,0] = predict_normalized_box[...,0] * orig_w\n",
    "        predict_normalized_box[...,1] = predict_normalized_box[...,1] * orig_h\n",
    "        predict_normalized_box[...,2] = predict_normalized_box[...,2] * orig_w\n",
    "        predict_normalized_box[...,3] = predict_normalized_box[...,3] * orig_h \n",
    "        H, W = orig_h, orig_w\n",
    "    predict_normalized_box = np.stack([predict_normalized_box[:,:,:,0]-0.5*predict_normalized_box[:,:,:,2],\n",
    "                                       predict_normalized_box[:,:,:,1]-0.5*predict_normalized_box[:,:,:,3],\n",
    "                                       predict_normalized_box[:,:,:,0]+0.5*predict_normalized_box[:,:,:,2],\n",
    "                                       predict_normalized_box[:,:,:,1]+0.5*predict_normalized_box[:,:,:,3]], axis=-1)\n",
    "    predict_object = np.reshape(predict_object, newshape=[-1, 1])\n",
    "    predict_class = np.reshape(predict_class, newshape=[-1, 1, nclasses])\n",
    "    predict_class = np.tile(predict_class, reps=[1, nboxes, 1])\n",
    "    predict_class = np.reshape(predict_class, newshape=[-1, nclasses])\n",
    "    predict_class_conf = np.max(predict_class, axis=-1)[:, None]\n",
    "    predict_class_idx = np.argmax(predict_class, axis=-1)[:, None]\n",
    "    scores = np.max(predict_class_conf * predict_object, axis=-1)\n",
    "    predict_normalized_box = np.reshape(predict_normalized_box, newshape=[-1, 4])\n",
    "    indices = tf.image.non_max_suppression(predict_normalized_box, scores=scores, iou_threshold=iou, score_threshold=score_threshold, max_output_size=100).numpy()\n",
    "    \n",
    "    boxes = np.int32(predict_normalized_box[indices])\n",
    "    probs = scores[indices]\n",
    "    category = np.reshape(predict_class_idx[indices], newshape=[-1])\n",
    "\n",
    "    img = np.uint8(img)\n",
    "    for idx, box in enumerate(boxes):\n",
    "        color_map = [(161, 244, 171), (179, 165, 215), (0, 0, 255), (144, 158, 187), (255, 0, 150), (239, 100, 124), (188, 128, 221), (156, 171, 161), (131, 180, 204), (187, 208, 123)]\n",
    "        bcolor = color_map[category[idx]]\n",
    "#         label_w = 150\n",
    "#         label_h = 45\n",
    "\n",
    "#         cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), bcolor, 8)\n",
    "        cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), bcolor, 2)\n",
    "        \n",
    "        cv2.rectangle(img, (box[0], box[1]), (box[0]+W//10, box[1]-H//32), (0, 255, 0), -1)\n",
    "#         cv2.rectangle(img, (box[0], box[1]), (box[0]+label_w, box[1]-label_h), (0, 255, 0), -1)\n",
    "        \n",
    "#         cv2.putText(img, f'{label_map[category[idx]]}', (box[0]+5, box[1]-3), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (10,10,10), 4, lineType=cv2.LINE_8)\n",
    "        cv2.putText(img, f'{label_map[category[idx]]}', (box[0]+5, box[1]-3), cv2.FONT_HERSHEY_SIMPLEX, .7, (10,10,10), 2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    if video:\n",
    "        return img\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.imshow(img)\n",
    "    plt.title('output')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'outputs/{np.random.randint(0, 10000)}.png')\n",
    "    plt.close()\n",
    "    \n",
    "def pipeline(frame):\n",
    "    h,w = frame.shape[:2]\n",
    "    disp = frame.copy()\n",
    "    frame = np.float32(cv2.resize(frame, (W,H)))\n",
    "    frame /= 255.\n",
    "    pred = model.predict(frame[None, ...])\n",
    "    output = visualize(disp, pred, iou=0.5, score_threshold=0.1, label_map=label_map, orig_h=h, orig_w=w)    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_map = {i:tuple(v) for i, v in enumerate(np.random.randint(100, 255, size=[10, 3]))}\n",
    "# color_map = list(color_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:03<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(np.random.randint(0, 10000, 500)):\n",
    "    img = val_images[i]\n",
    "    img = read_img(img)\n",
    "    disp = img.copy()\n",
    "    img /= 255.\n",
    "    pred = model.predict(img[None, ...])\n",
    "    x = visualize(disp, pred, iou=0.5, score_threshold=0.4, label_map=label_map, video=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/38035 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video darknet_toronto.mp4.\n",
      "Moviepy - Writing video darknet_toronto.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready darknet_toronto.mp4\n"
     ]
    }
   ],
   "source": [
    "clip = VideoFileClip('../../4k_driving/toronto.webm')\n",
    "res = clip.fl_image(pipeline)\n",
    "res.write_videofile('darknet_toronto.mp4', audio=False, threads=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/64673 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video darknet_vancouver.mp4.\n",
      "Moviepy - Writing video darknet_vancouver.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready darknet_vancouver.mp4\n"
     ]
    }
   ],
   "source": [
    "clip = VideoFileClip('../../4k_driving/vancouver.webm')\n",
    "res = clip.fl_image(pipeline)\n",
    "res.write_videofile('darknet_vancouver.mp4', audio=False, threads=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/62520 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video darknet_seattle.mp4.\n",
      "Moviepy - Writing video darknet_seattle.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  81%|████████  | 50577/62520 [58:06<13:38, 14.58it/s, now=None]"
     ]
    }
   ],
   "source": [
    "clip = VideoFileClip('../../4k_driving/seattle.webm')\n",
    "res = clip.fl_image(pipeline)\n",
    "res.write_videofile('darknet_seattle.mp4', audio=False, threads=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip('../../4k_driving/karol.mp4')\n",
    "res = clip.fl_image(pipeline)\n",
    "res.write_videofile('darknet_karol.mp4', audio=False, threads=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
